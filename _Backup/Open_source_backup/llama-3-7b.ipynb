{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d8b6d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import ast\n",
    "import random\n",
    "import lmstudio as lms\n",
    "\n",
    "from IPython.display import Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc610fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_link = pd.read_csv('../Data/postgenerate_gpt.csv')\n",
    "raw_tthc = pd.read_csv('../Data/raw_tthc.csv', dtype={'maThuTuc': str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9592d0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['link', 'Mã thủ tục hành chính liên quan', 'Số quyết định', 'Tên thủ tục', 'Cấp thực hiện', 'Loại thủ tục', 'Lĩnh vực', \n",
    "        'Trình tự thực hiện', 'Cách thức thực hiện', 'Thành phần hồ sơ', 'Đối tượng thực hiện', 'Cơ quan thực hiện', \n",
    "        'Cơ quan có thẩm quyền', 'Địa chỉ tiếp nhận hồ sơ', 'Cơ quan được ủy quyền', 'Cơ quan phối hợp', 'Kết quả thực hiện', \n",
    "        'Căn cứ pháp lý', 'Yêu cầu, điều kiện thực hiện', 'Từ khóa', 'Mô tả']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb273288",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_tthc.columns = cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9944a0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = []\n",
    "\n",
    "pattern.append(\"Bạn đang cố gắng xác định xem câu trả lời có hiểu sai ngữ cảnh và mục đích của câu hỏi hay không.\")\n",
    "pattern.append(\"Bạn đang cố gắng xác định xem câu trả lời có sự mâu thuẫn về mặt thực tế so với kiến thức liên quan hay không. Một số thông tin trong câu trả lời có thể đã được bịa ra.\")\n",
    "pattern.append(\"Bạn đang cố gắng xác định xem câu trả lời có quá chung chung hoặc quá chi tiết so với mức độ cụ thể phù hợp để trả lời câu hỏi hay không.\")\n",
    "pattern.append(\"Bạn đang cố gắng xác định xem câu trả lời có thể được suy ra đúng từ kiến thức liên quan hay không.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e5ae630",
   "metadata": {},
   "outputs": [],
   "source": [
    "example = []\n",
    "\n",
    "example.append(\"\"\"\n",
    "#Câu hỏi#: Giống chó hiếm nào được phát triển như một biến thể của Rat Terrier, Shiloh Shepherd hoặc American Hairless Terrier?\n",
    "#Câu trả lời#: American Hairless Terrier\n",
    "#Đánh giá của bạn#: Không\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "example.append(\"\"\"\n",
    "#Câu hỏi#: Các kênh thoát nước của New Orleans có cùng độ dài với kênh Augusta không?\n",
    "#Câu trả lời#: Không, các kênh thoát nước của New Orleans và kênh Augusta không có cùng độ dài. Kênh Orleans dài khoảng 3,6 dặm (5,8 km) trong khi kênh Augusta dài khoảng 7 dặm (11,3 km).\n",
    "#Đánh giá của bạn#: Có\n",
    "\n",
    "#Câu hỏi#: Tuyến đường cao tốc Hoa Kỳ nào cho phép tiếp cận Zilpo Road và cũng được gọi là Midland Trail?\n",
    "#Câu trả lời#: U.S Highway 70\n",
    "#Đánh giá của bạn#: Có\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "example.append(\"\"\"\n",
    "#Câu hỏi#: Superheaven và Oceansize thuộc thể loại nhạc nào?\n",
    "#Câu trả lời#: Superheaven và Oceansize thuộc thể loại nhạc rock.\n",
    "#Đánh giá của bạn#: Không\n",
    "\n",
    "#Câu hỏi#: Kōbō Abe và Agatha Christie có chung nghề nghiệp nào?\n",
    "#Câu trả lời#: Nhà viết kịch.\n",
    "#Đánh giá của bạn#: Không\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "example.append(\"\"\"\n",
    "#Câu hỏi#: Ban nhạc nào có nhiều thành viên hơn, Muse hay The Raconteurs?\n",
    "#Câu trả lời#: Muse có nhiều thành viên hơn The Raconteurs.\n",
    "#Đánh giá của bạn#: Có\n",
    "\n",
    "#Câu hỏi#: Mỏ nào hiện có giá trị hơn, Temagami-Lorrain Mine hay Meadowbank Gold Mine?\n",
    "#Câu trả lời#: Meadowbank Gold Mine, vì mỏ Meadowbank vẫn đang khai thác vàng trong khi mỏ Temagami-Lorrain đã ngừng hoạt động nhiều năm.\n",
    "#Đánh giá của bạn#: Không\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e82f73c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"temperature\": 0.7, \"maxTokens\": 32, \"topPSampling\": 0.9}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "598e6d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate_template = \\\n",
    "# \"\"\"Bạn sẽ đóng vai trò là một người đánh giá câu trả lời (answer judge). Với một câu hỏi và câu trả lời, mục tiêu của bạn là xác định xem câu trả lời được cung cấp có chứa thông tin không đúng sự thật hoặc thông tin ảo giác (hallucinated information) hay không. Bạn NÊN đưa ra đánh giá dựa trên các loại ảo giác (hallucination) sau đây và kiến thức thực tế.\n",
    "# {pattern}\n",
    "\n",
    "# #Câu hỏi#: {question}\n",
    "\n",
    "# #Câu trả lời#: {answer}\n",
    "\n",
    "# #Đánh giá của bạn#:\n",
    "\n",
    "# Bạn nên cố gắng hết sức để xác định xem câu trả lời có chứa thông tin không đúng sự thật hoặc thông tin ảo giác hay không. Câu trả lời bạn đưa ra PHẢI là \"Có\" hoặc \"Không\".\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1d8dbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_context = \"\"\"Bạn sẽ đóng vai trò là một người đánh giá câu trả lời (answer judge). Với một câu hỏi và câu trả lời, mục tiêu của bạn là xác định xem câu trả lời được cung cấp có chứa thông tin không đúng sự thật hoặc thông tin ảo giác (hallucinated information) hay không.\n",
    "{pattern}\n",
    "Bạn nên cố gắng hết sức để xác định xem câu trả lời có chứa thông tin không đúng sự thật hoặc thông tin ảo giác hay không. Câu trả lời bạn đưa ra bắt buộc CHỈ là \"Có\" hoặc \"Không\", và không giải thích gì thêm. Trả lời \"Có\" nếu câu trả lời chứa thông tin ảo giác, trả lời \"Không\" nếu câu trả lời không chứa thông tin ảo giác.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e81407ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_template = \\\n",
    "\"\"\"\n",
    "#Câu hỏi#: {question}\n",
    "\n",
    "#Câu trả lời#: {answer}\n",
    "\n",
    "#Đánh giá của bạn#:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8671b15d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done of 3717: 2010\r"
     ]
    }
   ],
   "source": [
    "model_name = \"llama-3-7b\"\n",
    "\n",
    "filename = f'{model_name}_evaluate.csv'\n",
    "\n",
    "model = lms.llm(model_name)\n",
    "\n",
    "cols = ['link', 'cauTraLoiDung', 'danhGiaDung', 'cauTraLoiAoGiac', 'pattern', 'danhGiaAoGiac']\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(filename)\n",
    "    if df.empty:\n",
    "        print(\"CSV file is empty\")\n",
    "        df = pd.DataFrame(columns=cols)\n",
    "except FileNotFoundError:\n",
    "    print(f\"File not found: {filename}\")\n",
    "    df = pd.DataFrame(columns=cols)\n",
    "    df.to_csv(filename, index=False)\n",
    "except pd.errors.EmptyDataError:\n",
    "    print(f\"File is completely empty: {filename}\")\n",
    "    df = pd.DataFrame(columns=cols)\n",
    "    df.to_csv(filename, index=False)\n",
    "\n",
    "for i in range(len(raw_link)):\n",
    "    if raw_link['link'][i] in list(df['link'].values):\n",
    "        continue\n",
    "\n",
    "    p = raw_link['pattern'][i]\n",
    "    question = raw_link['cauHoi'][i]\n",
    "    right_answer = raw_link['cauTraLoi'][i]\n",
    "    hallucinated_answer = raw_link['cauTraLoiAoGiac'][i]\n",
    "\n",
    "    context_right = evaluate_context.format(pattern=\"\")\n",
    "    context_hallucinated = evaluate_context.format(pattern=pattern[p])\n",
    "\n",
    "    prompt_right = evaluate_template.format(question=question, answer=hallucinated_answer)\n",
    "    prompt_hallucinated = evaluate_template.format(question=question, answer=hallucinated_answer)\n",
    "\n",
    "    try:\n",
    "        completion = model.respond(history={\"messages\": [\n",
    "            {\"role\": \"system\", \"content\": context_right},\n",
    "            {\"role\": \"user\", \"content\": prompt_right}\n",
    "        ]}, config=config)\n",
    "        output_right = str(completion)\n",
    "        completion = model.respond(history={\"messages\": [\n",
    "            {\"role\": \"system\", \"content\": context_hallucinated},\n",
    "            {\"role\": \"user\", \"content\": prompt_hallucinated}\n",
    "        ]}, config=config)\n",
    "        output_hallucinated = str(completion)\n",
    "    except Exception as e:\n",
    "        output_right = \"\"\n",
    "        output_hallucinated = \"\"\n",
    "        print(e)\n",
    "        break\n",
    "\n",
    "    results = [raw_link['link'][i], right_answer, output_right, hallucinated_answer, p, output_hallucinated]\n",
    "    df.loc[i, cols] = results    \n",
    "    df.to_csv(filename, index=False)\n",
    "\n",
    "    print(f'Done of {len(raw_link)}: {i+1}', end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d02cd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Có"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Có"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Dead kernel by interrupting so re-importing\n",
    "\n",
    "import pandas as pd\n",
    "from IPython.display import Markdown\n",
    "import random\n",
    "\n",
    "model_name = \"llama-3-7b\"\n",
    "\n",
    "filename = f'{model_name}_evaluate.csv'\n",
    "\n",
    "df = pd.read_csv(filename)\n",
    "\n",
    "display(Markdown(df['danhGiaDung'][random.randint(0, len(df)-1)]))\n",
    "print()\n",
    "display(Markdown(df['danhGiaAoGiac'][random.randint(0, len(df)-1)]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
